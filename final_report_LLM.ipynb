{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fe1dea4",
   "metadata": {},
   "source": [
    "# Final Project Report: Group X\n",
    "\n",
    "Technical report of the Final Project of the course Advanced Business Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df1dc5c",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Our project revolves around the use of advanced analytics and Natural Lenguage Processing tools for the recommendation of products close to expiration in supermarkets of the Sailing Group. By accessing the data available on the different APIs offered by the Sailing group, we set to focus on the real-time data of discounted products in order to provide tailored recommendation for the user based on data and feedback the user provides. Initially, we explore simple recommendation techniques based on quantitative metrics such as discounted price and we proceed to create a system that recommends products based on the user's specific wish. Finally, we focus on LLMs and how via prompt engineering they can offer a new prespective and window of opportunity for recommender systems, not only via single-item recommendation but also via generative approaches. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298507d3",
   "metadata": {},
   "source": [
    "### Motivation\n",
    "- Here we explin a bit of the motivation on why food waste and why using LLMs are a need promising alternative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406ff40f",
   "metadata": {},
   "source": [
    "### Data analysis and visualization\n",
    "- Initial call on the API\n",
    "- Retrieval of as much data from different stores as possible. \n",
    "- Provide stats on this data (Thor's visualization notebook)\n",
    "- Conclude explining challenges and possibilities (challenges: lots of already-made food, hard to categorize items and short selection of certain products like veggies)(possibilities: set step for further sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807a43b4",
   "metadata": {},
   "source": [
    "### Simple recommendation techniques\n",
    "- Andres's notebook on recommendation based on discount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149edc5c",
   "metadata": {},
   "source": [
    "### Word embedding for user-guided recommendation \n",
    "- Anika's clustering for \n",
    "- Thor's notebook for looking up similar products to a given word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dc2250",
   "metadata": {},
   "source": [
    "### LLMs and prompt engineering for advanced recommendation\n",
    "- Explain challenges and limitations of previous recommendation methods\n",
    "- Introduce recipe generation and user engagement ideas\n",
    "- Oriol's notebook\n",
    "\n",
    "\n",
    "While our earlier techniques successfully incorporated basic heuristics and word embeddings to support user-guided recommendations, these methods had several key limitations. Most notably, they required a predefined logic for mapping products and relied heavily on manual feature crafting or keyword matching. This proved inadequate when addressing ambiguous or open-ended user requests, such as “I want to cook a healthy vegetarian dinner” or “give me a lunch idea with what’s about to expire.”\n",
    "\n",
    "To overcome these challenges, we turned to large language models (LLMs) and prompt engineering. LLMs, with their capacity to understand and generate human-like text, enabled a more flexible and context-aware recommendation experience. Rather than matching based on word similarity, LLMs allowed us to interpret the user’s intent, understand constraints (e.g., dietary preferences, budget), and even generate novel recipe suggestions using the discounted products currently available in nearby stores.\n",
    "\n",
    "We designed prompts that incorporate user preferences, product metadata, and store availability data into a unified query. These prompts were dynamically constructed using Python and passed to the LLM via API calls. In practice, this allowed us to achieve two main innovations:\n",
    "\n",
    "Conversational Recommendation: Users could input free-text descriptions of their needs (e.g., “I have two kids and want something quick for dinner”), and the LLM would generate relevant product bundles or meals, incorporating discounted items retrieved via the Sailing Group APIs.\n",
    "\n",
    "Generative Recipes: By combining the list of available ingredients with user preferences, we generated simple recipes or meal ideas. For instance, if a user had yogurt, granola, and near-expiring berries, the model could suggest a breakfast parfait, along with preparation steps and nutritional insights.\n",
    "\n",
    "Despite their promise, LLMs also posed challenges:\n",
    "\n",
    "Hallucinations: Occasionally, the models recommended non-existent or unavailable items.\n",
    "\n",
    "API cost and latency: Each LLM call added overhead to system responsiveness, which would require optimization for real-time deployment.\n",
    "\n",
    "Lack of domain knowledge: Without fine-tuning, LLMs sometimes produced unrealistic combinations (e.g., pairing incompatible flavors or suggesting cooked versions of ready-to-eat meals).\n",
    "\n",
    "Nevertheless, our experiments clearly indicate that LLMs provide a powerful, human-centric layer for recommendation systems. They are particularly useful in contexts where creativity, adaptability, and user interaction are valued. Combined with structured data and traditional filtering mechanisms, LLMs can enhance both user engagement and product utilization—ultimately contributing to the broader goal of reducing food waste.\n",
    "\n",
    "To push beyond rule-based and embedding-based recommendations, we implemented an adaptive system leveraging OpenAI's large language models (LLMs) for real-time, personalized recipe generation. This system, called the AdaptiveRecipeAgent, is a feedback-aware, prompt-driven recipe generator that responds dynamically to a user’s ingredient availability and expressed preferences.\n",
    "\n",
    "The design centers around an evolving user profile (memory), which collects feedback across interactions and integrates it into future prompt construction. The memory stores banned ingredients, dietary restrictions, and preferences such as desired cuisine, dish type, and flavor profiles.\n",
    "\n",
    "Key Features:\n",
    "\n",
    "- Contextual Memory: Tracks banned ingredients and feedback-based preferences across multiple user inputs.\n",
    "\n",
    "- Dynamic Prompt Building: Uses real-time memory and available ingredients to construct effective prompts.\n",
    "\n",
    "- Conversational Adaptation: Can adapt recipes over multiple feedback cycles, making the experience more interactive and personalized.\n",
    "\n",
    "- Below is the core implementation, annotated for technical clarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eed4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client (you can also use openai.api_key = \"...\" style if preferred)\n",
    "client = OpenAI(api_key=\"your-api-key\")  # Replace with your actual key or use environment variable\n",
    "\n",
    "class AdaptiveRecipeAgent:\n",
    "    def __init__(self, ingredients):\n",
    "        self.ingredients = set(ingredients)\n",
    "        self.memory = {\n",
    "            \"feedback_log\": [],\n",
    "            \"banned_ingredients\": set(),\n",
    "            \"preferences\": [],\n",
    "            \"dietary_restrictions\": [],\n",
    "            \"cuisine\": None,\n",
    "            \"dish_type\": None\n",
    "        }\n",
    "\n",
    "    def update_from_feedback(self, feedback):\n",
    "        self.memory[\"feedback_log\"].append(feedback)\n",
    "        feedback_lower = feedback.lower()\n",
    "\n",
    "        for ingredient in self.ingredients:\n",
    "            if f\"don't use {ingredient.lower()}\" in feedback_lower or f\"no {ingredient.lower()}\" in feedback_lower:\n",
    "                self.memory[\"banned_ingredients\"].add(ingredient)\n",
    "\n",
    "        if \"simpler\" in feedback_lower or \"easy\" in feedback_lower:\n",
    "            self.memory[\"preferences\"].append(\"simpler recipe\")\n",
    "\n",
    "        if \"spicy\" in feedback_lower:\n",
    "            self.memory[\"preferences\"].append(\"make it spicy\")\n",
    "\n",
    "        if \"dairy-free\" in feedback_lower:\n",
    "            self.memory[\"dietary_restrictions\"].append(\"dairy-free\")\n",
    "\n",
    "        if \"gluten-free\" in feedback_lower:\n",
    "            self.memory[\"dietary_restrictions\"].append(\"gluten-free\")\n",
    "\n",
    "        self.memory[\"preferences\"].append(feedback.strip())\n",
    "\n",
    "    def build_prompt(self):\n",
    "        prompt = \"You are a creative chef. Generate a recipe based on the following:\\n\\n\"\n",
    "        prompt += f\"Available ingredients: {', '.join(self.ingredients - self.memory['banned_ingredients'])}\\n\"\n",
    "\n",
    "        if self.memory[\"dietary_restrictions\"]:\n",
    "            prompt += f\"Dietary restrictions: {', '.join(set(self.memory['dietary_restrictions']))}\\n\"\n",
    "\n",
    "        if self.memory[\"preferences\"]:\n",
    "            prompt += f\"User preferences: {', '.join(set(self.memory['preferences']))}\\n\"\n",
    "\n",
    "        if self.memory[\"cuisine\"]:\n",
    "            prompt += f\"Cuisine: {self.memory['cuisine']}\\n\"\n",
    "\n",
    "        if self.memory[\"dish_type\"]:\n",
    "            prompt += f\"Dish type: {self.memory['dish_type']}\\n\"\n",
    "\n",
    "        prompt += \"\\nPlease include:\\n- A recipe title\\n- List of ingredients\\n- Step-by-step instructions\"\n",
    "        return prompt\n",
    "\n",
    "    def generate_recipe(self, model=\"gpt-4\"):\n",
    "        prompt = self.build_prompt()\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert recipe generator that adapts based on user feedback.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=700\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2fedf8",
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIRemovedInV1\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m agent = AdaptiveRecipeAgent([\u001b[33m\"\u001b[39m\u001b[33mchicken\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrice\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbroccoli\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcheese\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmilk\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_recipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      5\u001b[39m agent.update_from_feedback(\u001b[33m\"\u001b[39m\u001b[33mDon\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt use cheese, I want it dairy-free and simpler.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(agent.generate_recipe())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mAdaptiveRecipeAgent.generate_recipe\u001b[39m\u001b[34m(self, model)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Sends the prompt to OpenAI’s API to generate a recipe.\"\"\"\u001b[39;00m\n\u001b[32m     66\u001b[39m prompt = \u001b[38;5;28mself\u001b[39m.build_prompt()\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m response = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are an expert recipe generator that adapts based on user feedback.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Encourages creativity\u001b[39;49;00m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m700\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Controls length of the output\u001b[39;49;00m\n\u001b[32m     76\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[33m'\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oriol\\anaconda3\\envs\\DL\\Lib\\site-packages\\openai\\lib\\_old_api.py:39\u001b[39m, in \u001b[36mAPIRemovedInV1Proxy.__call__\u001b[39m\u001b[34m(self, *_args, **_kwargs)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *_args: Any, **_kwargs: Any) -> Any:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol=\u001b[38;5;28mself\u001b[39m._symbol)\n",
      "\u001b[31mAPIRemovedInV1\u001b[39m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "agent = AdaptiveRecipeAgent([\"chicken\", \"rice\", \"broccoli\", \"cheese\", \"milk\"])\n",
    "\n",
    "print(agent.generate_recipe())\n",
    "\n",
    "agent.update_from_feedback(\"Don't use cheese, I want it dairy-free and simpler.\")\n",
    "print(agent.generate_recipe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313cc6da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
